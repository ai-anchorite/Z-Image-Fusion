{
  "9": {
    "inputs": {
      "images": [
        "43",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "$output.result"
    }
  },
  "40": {
    "inputs": {
      "vae_name": "ae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "$vae_name"
    }
  },
  "41": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "batch_size": 1
    },
    "class_type": "EmptySD3LatentImage",
    "_meta": {
      "title": "Canvas, $width, $height"
    }
  },
  "42": {
    "inputs": {
      "conditioning": [
        "58",
        0
      ]
    },
    "class_type": "ConditioningZeroOut",
    "_meta": {
      "title": "ConditioningZeroOut"
    }
  },
  "43": {
    "inputs": {
      "samples": [
        "44",
        0
      ],
      "vae": [
        "40",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "44": {
    "inputs": {
      "seed": 0,
      "steps": 9,
      "cfg": 1,
      "sampler_name": "res_multistep",
      "scheduler": "simple",
      "denoise": 1,
      "model": [
        "47",
        0
      ],
      "positive": [
        "58",
        0
      ],
      "negative": [
        "42",
        0
      ],
      "latent_image": [
        "41",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "Sampler, $seed, $steps, $cfg, $sampler_name, $scheduler"
    }
  },
  "45": {
    "inputs": {
      "text": "A beautiful landscape",
      "clip": [
        "57",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "$prompt.text!"
    }
  },
  "47": {
    "inputs": {
      "shift": 3,
      "model": [
        "64",
        0
      ]
    },
    "class_type": "ModelSamplingAuraFlow",
    "_meta": {
      "title": "ModelSampling, $shift"
    }
  },
  "52": {
    "inputs": {
      "lora_name": "none.safetensors",
      "strength_model": 0,
      "model": [
        "56",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "$lora1_name.lora_name!, $lora1_strength.strength_model!"
    }
  },
  "56": {
    "inputs": {
      "unet_name": "z_image_turbo-Q4_K_M.gguf"
    },
    "class_type": "UnetLoaderGGUF",
    "_meta": {
      "title": "$unet_name"
    }
  },
  "57": {
    "inputs": {
      "clip_name": "Qwen3-4B-Q6_K.gguf",
      "type": "lumina2"
    },
    "class_type": "CLIPLoaderGGUF",
    "_meta": {
      "title": "$clip_name"
    }
  },
  "58": {
    "inputs": {
      "randomize_percent": 50,
      "strength": 20,
      "noise_insert": "disabled",
      "steps_switchover_percent": 20,
      "seed": 0,
      "mask_starts_at": "beginning",
      "mask_percent": 0,
      "log_to_console": false,
      "conditioning": [
        "45",
        0
      ]
    },
    "class_type": "SeedVarianceEnhancer",
    "_meta": {
      "title": "SeedVariance, $sv_noise_insert.noise_insert, $sv_randomize_percent.randomize_percent, $sv_strength.strength, $sv_steps_switchover_percent.steps_switchover_percent, $sv_seed.seed, $sv_mask_starts_at.mask_starts_at, $sv_mask_percent.mask_percent"
    }
  },
  "60": {
    "inputs": {
      "lora_name": "none.safetensors",
      "strength_model": 0,
      "model": [
        "52",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "$lora2_name.lora_name!, $lora2_strength.strength_model!"
    }
  },
  "61": {
    "inputs": {
      "lora_name": "none.safetensors",
      "strength_model": 0,
      "model": [
        "60",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "$lora3_name.lora_name!, $lora3_strength.strength_model!"
    }
  },
  "62": {
    "inputs": {
      "lora_name": "none.safetensors",
      "strength_model": 0,
      "model": [
        "61",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "$lora4_name.lora_name!, $lora4_strength.strength_model!"
    }
  },
  "63": {
    "inputs": {
      "lora_name": "none.safetensors",
      "strength_model": 0,
      "model": [
        "62",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "$lora5_name.lora_name!, $lora5_strength.strength_model!"
    }
  },
  "64": {
    "inputs": {
      "lora_name": "none.safetensors",
      "strength_model": 0,
      "model": [
        "63",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "$lora6_name.lora_name!, $lora6_strength.strength_model!"
    }
  }
}
